import pandas as pd
import re
import numpy as np
from itertools import chain

df = pd.read_csv("jobkorea_nurse_merged.csv")
print("\nğŸ“Š This is the original dataset scrapped from jobkorea.co.kr, "
      "\n which is one of the most widely used recruitment website in Korea"
      "This is an exercise dataset, since it only contains records scrapped in one day")
# rename variable name
rename_dict = {
    "id": "job_id",
    "legacy_id": "job_legacyid",
    "title": "job_title",
    "company": "company_name",
    "postingCompany": "company_posting",
    "createdAt": "job_creat",
    "applicationStart": "job_applyon",
    "applicationEnd": "job_applyoff",
    "location": "job_location",
    "skills": "job_skill",
    "industry": "job_industry",
    "careerType": "job_type_code",
    "educationCode": "job_edu_code",
    "job_no": "job_no",
    "ê²½ë ¥": "job_expr",
    "í•™ë ¥": "job_edu",
    "ê³ ìš©í˜•íƒœ": "job_contract",
    "ê¸‰ì—¬": "job_pay",
    "ì‚°ì—…": "company_industry",
    "ì„¤ë¦½ë…„ë„": "company_foundedyear",
    "ê¸°ì—…í˜•íƒœ": "company_type",
    "ëª¨ì§‘ë¶„ì•¼": "job_field",
    "ëª¨ì§‘ì¸ì›": "job_quota",
    "ì§€ì›ììˆ˜": "applicants_total",
    "ì§€ì›_ë‚¨ì": "applicants_male",
    "ì§€ì›_ì—¬ì": "applicants_female",
    "ì‹œê°„": "job_time",
    "ì‹œê°„_ë¹„ê³ ": "job_time_note",
    "ì§€ì›_25ì„¸": "applicants_age_25below",
    "ì§€ì›_2630ì„¸": "applicants_age_2630",
    "ì§€ì›_3135ì„¸": "applicants_age_3135",
    "ì§€ì›_3640ì„¸": "applicants_age_3640",
    "ì§€ì›_4145ì„¸": "applicants_age_4145",
    "ì§€ì›_46ì„¸": "applicants_age_46above",
    "ì§€ì›_ê³ ì¡¸ë¯¸ë§Œ": "applicants_edu_nohs",
    "ì§€ì›_ê³ ì¡¸(ì˜ˆì •)": "applicants_edu_hs",
    "ì§€ì›_ì´ˆëŒ€ì¡¸(ì˜ˆì •)": "applicants_edu_sclg",
    "ì§€ì›_ëŒ€ì¡¸(ì˜ˆì •)": "applicants_edu_clg",
    "ì§€ì›_ì„ë°•ì‚¬(ì˜ˆì •)": "applicants_edu_grd",
    "ë³µë¦¬í›„ìƒ_ì—°ê¸ˆÂ·ë³´í—˜": "benefit_insurance",
    "ë³µë¦¬í›„ìƒ_ë³´ìƒÂ·ìˆ˜ë‹¹Â·ì§€ì›": "benefit_bonus",
    "ë³µë¦¬í›„ìƒ_íœ´ë¬´Â·íœ´ê°€Â·í–‰ì‚¬": "benefit_holiday",
    "ë³µë¦¬í›„ìƒ_ì‚¬ë‚´ì œë„Â·ì„±ì¥": "benefit_study",
    "ë³µë¦¬í›„ìƒ_í¸ì˜Â·ì—¬ê°€Â·ê±´ê°•": "benefit_convenience"
}
df.rename(columns=rename_dict, inplace=True)


df.to_csv("jobkorea_nurse_cleaned.csv", index=False, encoding="utf-8-sig")
print("âœ… Var name changed to: jobkorea_nurse_cleaned.csv")


# Values operation
df = pd.read_csv("jobkorea_nurse_cleaned.csv")

# Dates
for col in ["job_creat", "job_applyon", "job_applyoff"]:
    df[col] = pd.to_datetime(df[col], errors="coerce").dt.strftime("%Y-%m-%d")
df["company_foundedyear"] = df["company_foundedyear"].str.extract(r"(\d{4})").astype("Int64")

##A COMPANY##
#(1) company_type
# (1-i) specify keywords used in classification
type_keywords = {
    "ëŒ€ê¸°ì—…": "large",
    "ì¤‘ê²¬ê¸°ì—…": "midsize",
    "ì¤‘ì†Œê¸°ì—…": "small",
    "ë²¤ì²˜ê¸°ì—…": "venture",
    "ì™¸êµ­ê³„": "foreign",
    "ê°œì¸": "individual",
    "ë¹„ì˜ë¦¬": "nonprofit",
    "ê³µê³µê¸°ê´€": "public",
    "ê³„ì—´ì‚¬": "affiliate",
    "ìíšŒì‚¬": "affiliate"
}

# (1-ii) define and apply a function to categorize
def extract_company_type(text):
    if pd.isna(text):
        return "uncertain"
    for keyword, category in type_keywords.items():
        if keyword in text:
            return category
    return "uncertain"
df["company_type_eng"] = df["company_type"].apply(extract_company_type)

# (1-iii) create code for company types
category_map = {
    "large": 1,
    "midsize": 2,
    "small": 3,
    "venture": 4,
    "foreign": 5,
    "individual": 6,
    "nonprofit": 7,
    "public": 8,
    "affiliate": 9,
    "uncertain": 0
}
df["company_type_cat"] = df["company_type_eng"].map(category_map)

# (2) industry: use job_industry to classify instead of company_industry (reason: more detailed)
# (2-i) check all keywords
industry_col = "job_industry" if "job_industry" in df.columns else df.columns[0]
industry_vals = set()
for val in df[industry_col].astype(str):
    for kw in val.split('/'):
        kw = kw.strip()
        if kw and kw.lower() != 'nan':
            industry_vals.add(kw)
industry_list = sorted(industry_vals)
for i in industry_list:
    print(i)

# (2-ii) Classify special case first: pets related, beauty industry related,...
# (for example, ê°•ì•„ì§€(dog) í˜¸í…”(hotel), ì• ê²¬(dog)  ë¯¸ìš©(beautician) are not in hospitality industry or beauty industry)
pet_keywords = ["ì• ê²¬", "ê°•ì•„ì§€", "ë°˜ë ¤ë™ë¬¼", "ìˆ˜ì˜", "ë™ë¬¼ë³‘ì›"]
medical_keywords = ["ë³‘ì›", "ì˜ì›", "í´ë¦¬ë‹‰", "ì´ë¹„ì¸í›„ê³¼", "ë‚´ê³¼", "ì™¸ê³¼", "ì •í˜•ì™¸ê³¼", "ì†Œì•„ê³¼", "í”¼ë¶€ê³¼", "ì¹˜ê³¼"]
beauty_keywords = ["ë¯¸ìš©", "í”¼ë¶€", "ì—ìŠ¤í…Œí‹±", "ì„±í˜•", "ë³´í†¡ìŠ¤"]
pharmacy_keywords = ["ì œì•½","ë°”ì´ì˜¤"]
finance_keywords = ["ê¸ˆìœµ", "ë³´í—˜", "ì€í–‰", "ì¦ê¶Œ", "íšŒê³„", "ì¬ë¬´"]
education_keywords = ["êµìœ¡", "í•™ì›", "í•™êµ", "ìœ ì¹˜ì›", "ì–´ë¦°ì´ì§‘"]
it_keywords = ["it", "ict", "ì†Œí”„íŠ¸ì›¨ì–´", "í”Œë«í¼", "erp", "crm", "ai", "ì•±", "3dí”„ë¦°í„°","5g","APP"]
logistics_keywords = ["ë¬¼ë¥˜", "ë°°ì†¡", "ìš´ì†¡", "íƒë°°"]
manufacturing_keywords = ["ì œì¡°", "ê¸°ê³„", "ìë™í™”", "ì „ì", "ë°˜ë„ì²´"]
hospitality_keywords = ["í˜¸í…”", "ìˆ™ë°•", "ë ˆìŠ¤í† ë‘", "ìŒì‹ì ", "ì¹´í˜"]
construction_keywords = ["ê±´ì„¤", "ë¶€ë™ì‚°", "ê±´ì¶•", "ì¸í…Œë¦¬ì–´", "ì£¼íƒ"]
media_keywords = ["ë¯¸ë””ì–´", "ë°©ì†¡", "ê´‘ê³ ", "ì½˜í…ì¸ "]

# (2-iii) Ordered classification
def classify_industry(text):
    if pd.isnull(text):
        return "Unclassified"
    if any(kw in text for kw in pet_keywords):
        return "Animal_Pet"
    elif any(kw in text for kw in medical_keywords):
        return "Medical_Healthcare"
    elif any(kw in text for kw in beauty_keywords):
        return "Beauty_Cosmetic"
    elif any(kw in text for kw in pharmacy_keywords):
        return "Finance_Insurance"
    elif any(kw in text for kw in finance_keywords):
        return "Finance_Insurance"
    elif any(kw in text for kw in education_keywords):
        return "Education"
    elif any(kw in text for kw in it_keywords):
        return "IT_Digital"
    elif any(kw in text for kw in logistics_keywords):
        return "Logistics"
    elif any(kw in text for kw in manufacturing_keywords):
        return "Manufacturing"
    elif any(kw in text for kw in hospitality_keywords):
        return "Hospitality"
    elif any(kw in text for kw in construction_keywords):
        return "Construction_RealEstate"
    elif any(kw in text for kw in media_keywords):
        return "Media_Advertising"
    else:
        return "Other"

df["Industry_Standardized"] = df["job_industry"].apply(classify_industry)

# (3) location
admin_df = pd.read_csv("kor_admin.csv")

# (3-i) preparation for administration region information
def clean_suffix(name, field):
    if pd.isna(name):
        return ""
    name = re.sub(r"(ê´‘ì—­ì‹œ|íŠ¹ë³„ì‹œ|ìì¹˜ì‹œ|ìì¹˜ë„|íŠ¹ë³„ìì¹˜ë„)", "", name)
    name = re.sub(r"(ì‹œ|ë„|êµ°)$", "", name)
    if field in ["District", "City"] and len(name) == 2 and name.endswith("êµ¬"):
        return ""
    return name.strip()
admin_df["Province_Clean"] = admin_df["Province_Name_KR"].apply(lambda x: clean_suffix(x, "Province"))
admin_df["City_Clean"] = admin_df["City_Name_KR"].apply(lambda x: clean_suffix(x, "City"))
admin_df["District_Clean"] = admin_df["District_Name_KR"].apply(lambda x: clean_suffix(x, "District"))
duplicated_districts = admin_df["District_Clean"].duplicated(keep=False)
admin_df.loc[duplicated_districts, "District_Clean"] = ""


# (3-ii) keywords for both sides
province_keys = admin_df["Province_Clean"].dropna().unique().tolist()
city_keys = admin_df["City_Clean"].dropna().unique().tolist()
district_keys = admin_df["District_Clean"].dropna().unique().tolist()
df["match_text"] = df["job_location"].fillna('') + " " +  df["job_title"].fillna('')

# (3-iii) matching order: province, city, district
def match_region(row):
    text = row["match_text"]
    prov, city, dist = None, None, None

    for p in province_keys:
        if p and p in text:
            prov = p
            break

    if not prov:
        for c in city_keys:
            if c and c in text:
                city = c
                break

    if not prov and not city:
        for d in district_keys:
            if d and d in text:
                dist = d
                break

    return pd.Series([prov, city, dist])
df[["matched_province", "matched_city", "matched_district"]] = df.apply(match_region, axis=1)

city_to_prov_map = dict(zip(admin_df["City_Clean"], admin_df["Province_Clean"]))

# (3-iv) impute province and city
df.loc[
    df["matched_province"].isna() &  df["matched_city"].notna(),
    "matched_province"
] = df.loc[
    df["matched_province"].isna() &  df["matched_city"].notna(),
    "matched_city"
].map(city_to_prov_map)

df.loc[
    df["matched_province"].isna() & df["matched_district"].notna(),
    "matched_province"
] = df.loc[
    df["matched_province"].isna() & df["matched_district"].notna(),
    "matched_district"
].map(city_to_prov_map)
df.loc[
    df["matched_city"].isna() & df["matched_district"].notna(),
    "matched_city"
] = df.loc[
    df["matched_city"].isna() & df["matched_district"].notna(),
    "matched_district"
].map(city_to_prov_map)

prov_kr2en = admin_df.dropna(subset=["Province_Clean", "Province_Name"]).drop_duplicates("Province_Clean").set_index("Province_Clean")["Province_Name"].to_dict()
city_kr2en = admin_df.dropna(subset=["City_Clean", "City_Name"]).drop_duplicates("City_Clean").set_index("City_Clean")["City_Name"].to_dict()

# åŒ¹é…è‹±æ–‡å­—æ®µ
df["company_province"] = df["matched_province"].map(prov_kr2en)
df["company_city"] = df["matched_city"].map(city_kr2en)

##B JOB##
# (1) job_field
# (1-i) specify keywords used in classification
job_field_categories = {
    "clinical_nurse": {
        "cat": 1,
        "keywords": ["ê°„í˜¸ì‚¬", "ë³‘ë™", "ì™¸ë˜", "ìˆ˜ìˆ ì‹¤", "ì¤‘í™˜ìì‹¤", "ì‘ê¸‰ì‹¤", "íšŒë³µì‹¤", "ê²€ì§„ì„¼í„°", "ì…ì›", "ì‘ê¸‰"],
        "label": "Clinical_Nurse"
    },
    "assistant_staff": {
        "cat": 2,
        "keywords": ["ì¡°ë¬´ì‚¬", "ê°„í˜¸ì¡°ë¬´ì‚¬", "ì¹˜ê³¼ì¡°ë¬´ì‚¬", "ë³‘ì›ë³´ì¡°", "ê²€ì‚¬ë³´ì¡°", "ê¸°ë¡", "ë„ìš°ë¯¸"],
        "label": "Assistant"
    },
    "nonclinical_admin": {
        "cat": 3,
        "keywords": ["ìƒë‹´", "ì½”ë””", "ì½œì„¼í„°", "ê³ ê°ê´€ë¦¬", "ì¹´ìš´í„°", "ì ‘ìˆ˜", "ë³´í—˜", "ì‹¬ì‚¬", "í–‰ì •", "ìˆ˜ë‚©", "ì²­êµ¬", "ì„œë¥˜"],
        "label": "Administration"
    },
    "research_edu_support": {
        "cat": 4,
        "keywords": ["ì—°êµ¬", "êµìœ¡", "ì„ìƒì‹œí—˜", "ì»¨ì„¤íŒ…", "ê¸°ìˆ ì§€ì›", "ì œí’ˆêµìœ¡", "ì˜ì—…ì§€ì›"],
        "label": "Tech_Edu"
    },
    "veterinary": {
        "cat": 5,
        "keywords": ["ìˆ˜ì˜", "ë™ë¬¼ë³‘ì›", "ìˆ˜ì˜í…Œí¬ë‹ˆì…˜"],
        "label": "Veterinary"
    }
}

# (1-ii) define and apply a function to categorize
df["job_field_cat"] = 0
df["job_field_catname"] = "other"
for category in job_field_categories.values():
    cat = category["cat"]
    label = category["label"]
    for kw in category["keywords"]:
        mask = df["job_field"].fillna("").str.contains(kw, case=False, na=False)
        df.loc[mask, "job_field_cat"] = cat
        df.loc[mask, "job_field_catname"] = label


# (2) job_pay
# (2-i) operations: extract range of wage from text; create lower bound and upper bound; normalize to monthly pay
def parse_salary(s):
    if pd.isna(s):
        return np.nan, np.nan, np.nan
    s = s.strip()
    s_raw = s

    is_annual = "ì—°ë´‰" in s
    is_monthly = "ì›”ê¸‰" in s or "ì›”" in s

    numbers = re.findall(r"(\d+)", s)
    numbers = list(map(int, numbers))

    lower, upper = np.nan, np.nan
    if len(numbers) == 1:
        lower = numbers[0]
    elif len(numbers) >= 2:
        lower, upper = numbers[0], numbers[1]

    if is_annual:
        if not np.isnan(lower):
            lower = round(lower / 12)
        if not np.isnan(upper):
            upper = round(upper / 12)

    return lower, upper, s_raw if any(kw in s for kw in ["ë©´ì ‘", "íšŒì‚¬ë‚´ê·œ", "í˜‘ì˜", "ê²°ì •", "ìˆ˜ìŠµ"]) else np.nan

df[["job_pay_lower", "job_pay_upper", "job_pay_note"]] = df["job_pay"].apply(
    lambda x: pd.Series(parse_salary(x))
)


# (3)job_time
# (3-i) operations: extract work days and hours from text;
def parse_job_time(s):
    if pd.isna(s):
        return np.nan, np.nan, np.nan

    s = s.strip()

    weekday_count = np.nan
    dayon = np.nan
    dayoff = np.nan

    weekdays_full = "ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼"
    range_match = re.search(r"([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼])\s*~\s*([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼])", s)
    list_match = re.findall(r"[ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]", s)
    week5_match = re.search(r"ì£¼\s*5ì¼", s)

    if week5_match:
        weekday_count = 5
    elif range_match:
        start = weekdays_full.index(range_match.group(1))
        end = weekdays_full.index(range_match.group(2))
        if start <= end:
            weekday_count = end - start + 1
    elif list_match:
        weekday_count = len(set(list_match))

    time_match = re.search(r"(\d{1,2}:\d{2})\s*~\s*(\d{1,2}:\d{2})", s)
    if time_match:
        dayon = time_match.group(1)
        dayoff = time_match.group(2)

    return weekday_count, dayon, dayoff

df[["job_weekday", "job_dayon", "job_dayoff"]] = df["job_time"].apply(
    lambda x: pd.Series(parse_job_time(x))
)

# (4) job_skill
# (4-i) specify keywords for skills of nurse at workplace
SKILL_CLASS_KEYWORDS = {
    "Injection_BloodDraw_Infusion": [
        "ì£¼ì‚¬", "IVì˜í•˜ëŠ”", "ì±„í˜ˆ", "ìˆ˜ì•¡", "ìˆ˜ì•¡ì£¼ì‚¬", "í˜ˆê´€í™•ë³´", "í˜ˆì•¡ì±„ì·¨", "IV", "infusion", "injection", "ì±„í˜ˆê°„í˜¸ì‚¬", "ìˆ˜ì•¡ì‹¤", "í˜ˆê´€ì£¼ì‚¬"
    ],
    "Medical_Equipment_Operation_Management": [
        "ì˜ë£Œê¸°ê¸°", "ì˜ë£Œê¸°ê¸°ê´€ë¦¬", "ì˜ë£Œê¸°ê¸°ì¡°ì‘", "ì¥ë¹„", "ì¥ë¹„ê´€ë¦¬", "ê¸°ê¸°ê´€ë¦¬", "ê¸°ê¸°", "ì¥ë¹„ë„ì…", "ì†Œëª¨í’ˆì¬ê³ ê´€ë¦¬", "ê¸°ê¸°ì ê²€", "ì†Œëª¨í’ˆê´€ë¦¬", "ì¥ë¹„ìœ ì§€ë³´ìˆ˜", "ê¸°ê³„ì„¤ê³„", "ì¥ë¹„ì ê²€", "ê¸°ê³„ê³µí•™"
    ],
    "Surgical_Preparation_Assistance": [
        "ìˆ˜ìˆ ", "ìˆ˜ìˆ ì¤€ë¹„", "ìˆ˜ìˆ ë³´ì¡°", "ìˆ˜ìˆ ì‹¤", "ìˆ˜ìˆ íŒŒíŠ¸", "ìˆ˜ìˆ ì¥ë¹„", "ë§ˆì·¨ë³´ì¡°", "ìˆ˜ìˆ í™˜ìê´€ë¦¬", "ìˆ˜ìˆ ì–´ì‹œìŠ¤íŠ¸", "ìˆ˜ìˆ ì¤€ë¹„ë¬¼", "ìˆ˜ìˆ ë³´ì¡°ê°„í˜¸ì‚¬", "ìˆ˜ìˆ í™˜ìì´ì†¡", "ë§ˆì·¨"
    ],
    "Emergency_Response_CPR": [
        "ì‘ê¸‰ì²˜ì¹˜", "CPR", "ì‹¬íì†Œìƒìˆ ", "ì‘ê¸‰êµ¬ì¡°ì‚¬", "ì‘ê¸‰ì‹¤", "ì‘ê¸‰ì§„ë£Œ", "ì‘ê¸‰í™˜ì", "ì‘ê¸‰ê°„í˜¸ì‚¬", "ì‘ê¸‰ì¤‘í™˜ìê³¼", "ì‘ê¸‰ì¡°ì¹˜", "ì‘ê¸‰ì§€ì›", "ì‹¬ì¥ì¶©ê²©ê¸°"
    ],
    "Medication_Administration": [
        "ì•½ì œê´€ë¦¬", "íˆ¬ì•½", "íˆ¬ì•½ê´€ë¦¬", "ì•½í’ˆì£¼ë¬¸", "ì•½êµ­ì—…ë¬´", "ì²˜ë°©", "ì•½í’ˆê´€ë¦¬", "ì•½í’ˆ", "ì¡°ì œ", "íˆ¬ì•½ì‹¤", "ì•½ë¬¼ê°ì‹œ", "ì•½í’ˆì¬ê³ ê´€ë¦¬", "ì•½ì œ", "ì•½ë¬¼ê´€ë¦¬", "ì¡°ì œì‹¤"
    ],
    "PR_Marketing_NewMedia_Content": [
        "í™ë³´", "ë§ˆì¼€íŒ…", "í”„ë¡œëª¨ì…˜", "ë¸Œëœë”©", "ê´‘ê³ ", "ë¸”ë¡œê·¸", "ìœ íŠœë¸Œ", "SNS", "ì½˜í…ì¸ ", "ì¹´ë“œë‰´ìŠ¤", "Content", "Branding", "Promotion", "YouTube", "SNSì»¨í…ì¸ ", "ë§ˆì¼€í„°", "ë¸”ë¡œê·¸ìš´ì˜", "ìœ íŠœë¸Œì˜ìƒì œì‘", "SNSë§ˆì¼€íŒ…", "í™ë³´ë§ˆì¼€íŒ…"
    ],
    "Customer_Patient_Communication_Consultation": [
        "ìƒë‹´", "ê³ ê°ìƒë‹´", "í™˜ììƒë‹´", "ë³´í˜¸ììƒë‹´", "ê²Œì‹œíŒìƒë‹´", "ìƒë‹´ì›", "ê°„í˜¸ìƒë‹´ì›", "Customer Service", "Consultation", "ê³ ê°ë¯¸íŒ…", "ê³ ê°ë¬¸ì˜ì‘ëŒ€", "ê³ ê°ì‘ëŒ€", "ê³ ê°ì¼€ì–´", "ìƒë‹´ê°„í˜¸ì‚¬"
    ],
    "Education_Training": [
        "êµìœ¡", "ê°•ì‚¬", "íŠ¸ë ˆì´ë„ˆ", "êµìœ¡ìë£Œ", "êµìœ¡ì „ë‹´ê°„í˜¸ì‚¬", "êµìœ¡ì§€ì›", "ì‹¤ìŠµì§€ë„", "ì—°ìˆ˜", "ê°•ì˜", "Lecture", "Training", "Instructor", "êµìœ¡ìë£Œì‘ì„±", "êµìœ¡ìë£Œì œì‘", "êµìœ¡ìƒë‹´ê°„í˜¸ì‚¬"
    ],
    "Medical_Testing_Diagnostics": [
        "ê²€ì‚¬", "ê²€ì§„", "ì§„ë‹¨", "ê²€ì‚¬ì‹¤", "ì§„ë‹¨ê²€ì‚¬", "ì´ˆìŒíŒŒ", "ë‚´ì‹œê²½", "ì˜ìƒì˜í•™", "ì˜ìƒì´¬ì˜", "ì˜ìƒí¸ì§‘", "Lab", "Test", "Ultrasound", "Endoscope", "ê²€ì•ˆ", "í˜ˆì•¡ê²€ì‚¬", "ì˜ìƒì˜í•™ê³¼", "ê²€ì²´ë¶„ì„", "ì„ìƒë³‘ë¦¬", "ì„ìƒì‹œí—˜", "ìƒí™”í•™"
    ],
    "Record_Document_Management": [
        "ê¸°ë¡ê´€ë¦¬", "ë¬¸ì„œ", "ë¬¸ì„œì‘ì„±", "ë¬¸ì„œê´€ë¦¬", "ì „ì‚°", "ë°ì´í„°ê´€ë¦¬", "í”„ë¡œê·¸ë¨", "ì‹œìŠ¤í…œ", "ì†Œí”„íŠ¸ì›¨ì–´", "ì›Œë“œì‘ì„±", "ì ‘ìˆ˜", "ì‚¬ë¬´", "ì •ë³´ê´€ë¦¬", "Data", "Record", "EMR", "OCS", "Excel", "ì„œë¥˜", "ì„œë¥˜ê´€ë¦¬", "ì„œë¥˜ì‘ì„±", "í–‰ì •", "í–‰ì •ì§€ì›"
    ],
    "Patient_Management_Basic_Nursing": [
        "í™˜ìê´€ë¦¬", "ë³‘ë™ê°„í˜¸", "í™œë ¥ì§•í›„", "ì²´ìœ„ë³€ê²½", "ì„ì…˜", "ë°°ë‡¨ê´€ë¦¬", "ì´ì†¡", "ë³´í˜¸ììƒë‹´", "ë³‘ë™ë³´ì¡°", "ë³‘ë™ê·¼ë¬´", "ë³‘ë™", "ê°„í˜¸ë³´ì¡°", "ê°„í˜¸ì¡°ë¬´ì‚¬", "ê°„í˜¸ì¡°ë¬´", "ê°„í˜¸ì§€ì›", "ê°„í˜¸ì‚¬ë³´ì¡°", "í™˜ìì´ë™", "ê°„ë³‘", "í™œë ¥ì¸¡ì •", "í™œë ¥ì§•í›„ì¸¡ì •"
    ],
    "Infection_Control_Sterilization": [
        "ê°ì—¼ê´€ë¦¬", "ê°ì—¼ì˜ˆë°©", "ë©¸ê· ", "ìœ„ìƒê´€ë¦¬", "ì¤‘ì•™ë©¸ê· íŒŒíŠ¸", "í™˜ê²½ê´€ë¦¬", "í™˜ê²½ì •ë¦¬", "í™˜ê²½ë¯¸í™”", "ì†Œë…", "Sterilization", "Disinfection", "ê°ì—¼ê´€ë¦¬ê°„í˜¸ì‚¬", "ì†Œë…ê´€ë¦¬", "ì†Œë…ì‹¤", "ê°ì—¼"
    ],
    "Inventory_Supply_Management": [
        "ë¬¼í’ˆê´€ë¦¬", "ì¬ê³ ê´€ë¦¬", "ì†Œëª¨í’ˆì¬ê³ ê´€ë¦¬", "ì•½í’ˆì£¼ë¬¸", "ì•½êµ­ì—…ë¬´", "ì¬ë£Œê´€ë¦¬", "ìì¬ê´€ë¦¬", "ì•½í’ˆì¬ê³ ê´€ë¦¬", "ê¸°êµ¬ê´€ë¦¬", "ì†Œëª¨í’ˆê´€ë¦¬", "ë¬¼í’ˆì •ë¦¬"
    ],
    "Medical_Billing_Insurance": [
        "ë³´í—˜ê¸ˆ", "ë³´í—˜ê¸ˆì²­êµ¬", "ë³´í—˜ì„¤ê³„", "ë³´í—˜ì„¤ê³„ì‚¬", "ë³´í—˜ì˜ì—…", "ë³´í—˜ë³´ì¥ë¶„ì„", "ë³´í—˜ì»¨ì„¤íŒ…", "ë³´í—˜tm", "ì§„ë£Œë¹„ì²­êµ¬", "ì‹¤ì†", "ì‹¤ì†ë³´í—˜", "ì˜ë£Œë¹„", "ì˜ë£Œë¹„ì •ì‚°", "ë³´í—˜", "ë³´í—˜ê¸ˆì²­êµ¬", "ë³´í—˜ê´€ë¦¬"
    ],
    "Foreign_Language_International_Affairs": [
        "ì˜ì–´", "ì˜ì–´ê°•ì‚¬", "ì˜ì–´ê¶Œ", "êµ­ì œí•™êµ", "ì™¸êµ­ì¸í•™êµ", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´", "í†µë²ˆì—­", "ì˜ë¬¸", "ì˜ë¬¸í•´ì„", "ì™¸êµ­ì–´", "êµ­ì œí™˜ì", "International", "Foreign Language"
    ],
    "Nursing_Assessment_Planning": [
        "ê°„í˜¸í‰ê°€", "ê±´ê°•ì§„ë‹¨", "ê±´ê°•ê²€ì§„", "ê±´ê°•ê´€ë¦¬", "ê±´ê°•ìƒë‹´", "ê±´ê°•ì¦ì§„", "ê±´ê°•ì¦ì§„ì„¼í„°", "ê°„í˜¸ê³„íš", "ê°„í˜¸ê³¼ì •", "ê°„í˜¸í‰ê°€ê°„í˜¸ì‚¬", "ê±´ê°•ì •ë³´"
    ],
    "Teaching_Material_Instructional_Design": [
        "êµìœ¡ìë£Œì‘ì„±", "êµìœ¡ìë£Œì œì‘", "ê°•ì˜ìë£Œ", "ê°•ì˜ë…¸íŠ¸", "êµìœ¡ì•ˆë‚´", "êµì¬ê°œë°œ", "ì½˜í…ì¸ ë””ìì¸", "ê°•ì˜ê³„íšì„œ", "êµìœ¡ì½˜í…ì¸ ", "êµì•ˆ"
    ],
    "Quality_Management_Compliance": [
        "QA", "QC", "ì¸ì¦", "ê°ì‚¬", "audit", "compliance", "ì‹¬ì‚¬", "ì‹¬ì‚¬ëŒ€ì‘", "í’ˆì§ˆê´€ë¦¬", "í’ˆì§ˆê²€ì‚¬", "í’ˆì§ˆë³´ì¦", "í’ˆì§ˆê°œì„ ", "í’ˆì§ˆë‹´ë‹¹ì", "í’ˆì§ˆì§€ì›"
    ],
    "Home_Community_Nursing": [
        "ë°©ë¬¸ê°„í˜¸", "ë°©ë¬¸ê°„í˜¸ì‚¬", "ìš”ì–‘", "ìš”ì–‘ë³´í˜¸ì‚¬", "ê°€ì •ê°„í˜¸", "ì§€ì—­ê°„í˜¸", "ë°©ë¬¸ìš”ì–‘ì„¼í„°", "í™ˆì¼€ì–´", "ë°©ë¬¸", "ì§€ì—­ë³´ê±´", "Community Nursing", "Home Care"
    ],
    "Beauty_Skin_Esthetics": [
        "í”¼ë¶€", "í”¼ë¶€ê´€ë¦¬", "í”¼ë¶€ë¯¸ìš©", "ì—ìŠ¤í…Œí‹±", "ë ˆì´ì €", "í”¼ë¶€ì¥ë¹„", "ë·°í‹°", "ë¯¸ìš©ê´€ë¦¬", "ë·°í‹°ì„±í˜•", "ë·°í‹°íë§ë°”ë””ì¼€ì–´", "ë°”ë””ì¼€ì–´", "ìŠ¤í‚¨ì¼€ì–´", "ë ˆì´ì €ì‹¤", "ë ˆì´ì €ì–´ì‹œ", "ë¯¸ìš©ì˜ì›", "ì„±í˜•", "ì„±í˜•ì™¸ê³¼", "ë¯¸ìš©", "í”¼ë¶€ê³¼"
    ],
    "Veterinary_Animal_Care": [
        "ë™ë¬¼ê°„í˜¸", "ë™ë¬¼ê°„í˜¸ì‚¬", "ìˆ˜ì˜ê°„í˜¸ì‚¬", "ë™ë¬¼ê°„í˜¸ë³µì§€ì‚¬", "ë™ë¬¼ë³‘ì›", "ìˆ˜ì˜", "ìˆ˜ì˜í…Œí¬ë‹ˆì…˜", "ë°˜ë ¤ë™ë¬¼ê´€ë¦¬", "ë™ë¬¼ì§„ë£Œ", "ìˆ˜ì˜í•™", "ì• ê²¬ê´€ë¦¬", "ì• ê²¬ìœ ì¹˜ì›", "ì• ê²¬í˜¸í…”"
    ],
    "Project_Management_RnD": [
        "í”„ë¡œì íŠ¸", "ì—°êµ¬", "ì—°êµ¬ê°œë°œ", "ì‹¤í—˜", "ë…¼ë¬¸ì‘ì„±", "ë°ì´í„°ë¶„ì„", "ê°œë°œ", "ì œí’ˆì„¤ê³„", "ê°œë°œê´€ë¦¬", "ê³¼ì œê´€ë¦¬", "Lab", "R&D"
    ],
    "Administration_Clerical_Support": [
        "í–‰ì •", "í–‰ì •ì§€ì›", "ì‚¬ë¬´", "ì‚¬ë¬´ì§€ì›", "ì ‘ìˆ˜", "ë¬¸ì„œ", "ë¬¸ì„œì‘ì„±", "ë¬¸ì„œê´€ë¦¬", "ì „ì‚°", "ì •ë³´ê´€ë¦¬", "ë°ì´í„°ê´€ë¦¬", "ì›Œë“œì‘ì„±", "Data Entry", "Administration"
    ],
    "Sales_Business_Development": [
        "ì˜ì—…", "ì˜ì—…ê´€ë¦¬", "ì˜ì—…ë¶€", "ì˜ì—…ì „ëµ", "ì˜ì—…ì§€ì›", "ê³ ê°ê´€ë¦¬", "ê³ ê°ìƒë‹´", "ê³ ê°ê´€ê³„ê´€ë¦¬", "ê³ ê°ë¯¸íŒ…", "ê³ ê°ì„œë¹„ìŠ¤", "ê³ ê°ì„¼í„°", "ê³ ê°ì¼€ì–´", "ë§ˆì¼“ë¦¬ì„œì¹˜", "ì‹ ê·œê³ ê°ë°œêµ´", "ê³ ê°ìœ ì¹˜", "Sales", "Business Development"
    ],
    "IT_Systems_Data_Analysis": [
        "EMR", "OCS", "CRM", "ERP", "Excel", "ì „ì‚°", "ë°ì´í„°ê´€ë¦¬", "í”„ë¡œê·¸ë¨", "ì‹œìŠ¤í…œ", "ì†Œí”„íŠ¸ì›¨ì–´", "IT", "SaaS", "ë„¤íŠ¸ì›Œí¬", "Data Analysis"
    ],
    "Pharmacy_Consulting_Services": [
        "ì•½ì‚¬", "ì•½êµ­", "ì•½êµ­ì—…ë¬´", "ì•½í’ˆì£¼ë¬¸", "íˆ¬ì•½", "íˆ¬ì•½ê´€ë¦¬", "ì•½ì œê´€ë¦¬", "ì¡°ì œ", "Dispensing", "Pharmacy"
    ],
    "HR_Recruitment": [
        "ì¸ì‚¬", "ì¸ì‚¬ê´€ë¦¬", "ì¸ì¬ì±„ìš©", "ì±„ìš©ë‹´ë‹¹", "HR", "HRD", "HRM", "Recruitment", "Human Resource"
    ],
    "Nursing_Support_Assistance": [
        "ê°„í˜¸ë³´ì¡°", "ê°„í˜¸ì¡°ë¬´ì‚¬", "ê°„í˜¸ì¡°ë¬´", "ê°„í˜¸ì¡°ë¬´ì‚¬ë‹˜", "ê°„í˜¸ì¡°ë¬´ì‚¬(ì •ê·œì§)", "ê°„í˜¸ì¡°ë¬´ì‚¬(íŒŒíŠ¸íƒ€ì„)", "ì¡°ë¬´ì‚¬", "ì¡°ë¬´", "ê°„í˜¸ì§€ì›", "ë³´ì¡°"
    ],
    "Environment_Safety_Cleaning_Mgmt": [
        "í™˜ê²½ê´€ë¦¬", "ì²­ê²°ê´€ë¦¬", "ì•ˆì „ê´€ë¦¬", "ìœ„ìƒê´€ë¦¬", "í™˜ê²½ì •ë¦¬", "ì²­ì†Œ", "ë©¸ê· ", "ì‹œì„¤ê´€ë¦¬", "ì²­ì†Œê´€ë¦¬", "ìœ„ìƒ", "ì²­ì†Œì›", "Safety", "Environment"
    ],
    "Hospital_Management_Operations": [
        "ì˜ë£Œê²½ì˜", "ë³‘ì›ìš´ì˜", "ê²½ì˜", "ê²½ì˜ê´€ë¦¬", "ê²½ì˜ì§€ì›", "ê²½ì˜ì „ëµ", "ì‚¬ì—…ê³„íš", "ìš´ì˜ê´€ë¦¬", "ìš´ì˜ì§€ì›", "ë³¸ë¶€ì¥", "ê´€ë¦¬ì", "ê´€ë¦¬ìê¸‰", "ê´€ë¦¬íŒ€", "Hospital Management"
    ],
    "Finance_Accounting": [
        "íšŒê³„", "íšŒê³„ê´€ë¦¬", "íšŒê³„í•™", "ê²°ì‚°", "ì˜ˆì‚°ê´€ë¦¬", "ì˜ˆì‚°ìˆ˜ë¦½", "ì¬ë¬´", "ì¬ë¬´íšŒê³„", "ì¬ë¬´ë‹´ë‹¹", "Accounting", "Finance"
    ],
    "Procurement_Supply_Chain": [
        "êµ¬ë§¤", "êµ¬ë§¤ë‹´ë‹¹", "êµ¬ë§¤íŒ€", "êµ¬ë§¤ìì¬", "êµ¬ë§¤ìì¬ê·¸ë£¹", "ë°œì£¼", "ë°œì£¼ê´€ë¦¬", "ë°œì£¼ì„œì‘ì„±", "Procurement", "Supply Chain"
    ],
    "Transportation_Logistics": [
        "ìš´ì†¡", "ë°°ì†¡", "ìš´ë°˜", "ë¬¼ë¥˜", "ë¬¼ë¥˜ê´€ë¦¬", "ë¬¼ë¥˜íŒ€", "ìš´ì†¡ê´€ë¦¬", "Logistics", "Transportation"
    ],
    "Catering_Nutrition_Management": [
        "ê¸‰ì‹ê´€ë¦¬", "ì‹ë‹¨ê´€ë¦¬", "ì‹ìì¬ê´€ë¦¬", "ì‹ìì¬ê²€ìˆ˜", "ì‹ìŒë£Œ", "ì¡°ë¦¬", "ì¡°ë¦¬ì‚¬", "ë°°ì‹", "Nutrition", "Catering"
    ],
    "Dermatology_Medical_Esthetics_Dept": [
        "í”¼ë¶€ê³¼", "ë¯¸ìš©ì˜ì›", "ì¨ì˜ì›", "ë¹„ë”ë‰´ì˜ì›", "ì„±í˜•ì™¸ê³¼", "ì„±í˜•", "ì—ìŠ¤í…Œí‹±"
    ],
    "Other_Unclassified": [
        "AE", "PA", "School", "FMë§¤ë‹ˆì €", "TSMC", "Nì „ë‹´", "b2b", "Generalist", "APM", "Affairs", "IVì˜í•˜ëŠ”", "Part", "S", "amd", "ba", "Product", "C", "Associate"
    ]
}
def classify_job_skills(text, class_keywords):
    result = set()
    if pd.isnull(text):
        return []
    for kw in str(text).replace('/', ',').replace('|', ',').split(','):
        kw = kw.strip()
        if not kw:
            continue
        for class_name, keywords in class_keywords.items():
            for match_kw in keywords:
                if match_kw.lower() in kw.lower():
                    result.add(class_name)
    return list(result)

# (4-ii) create category variables (two forms)
df['job_task_vec'] = df['job_skill'].apply(lambda x: classify_job_skills(x, SKILL_CLASS_KEYWORDS))
df['job_task_str'] = df['job_task_vec'].apply(lambda x: '|'.join(x) if x else '')

# (4-iii) encode the tasks and get codebook
all_labels = set(chain.from_iterable(df['job_task_vec']))
label_to_code = {label: idx for idx, label in enumerate(sorted(all_labels))}
def encode_labels(label_list):
    codes = [label_to_code[label] for label in label_list if label in label_to_code]
    return codes, '|'.join(str(c) for c in codes)

df[['job_task_codevec', 'job_task_codestr']] = df['job_task_vec'].apply(
    lambda x: pd.Series(encode_labels(x))
)

codebook = pd.DataFrame([
    {'label': label, 'code': code}
    for label, code in label_to_code.items()
]).sort_values('code').reset_index(drop=True)
print(codebook)

# (5) basic requirement
# (5-i) experience
def extract_min_experience(text):
    if pd.isna(text):
        return 0
    numbers = list(map(int, re.findall(r'\d+', text)))
    if len(numbers) == 0:
        return 0
    return min(numbers)

df["job_experience"] = df["job_expr"].apply(extract_min_experience)

# (5-ii) cleaned education mapping
edu_map = [
    ("ì´ˆëŒ€ì¡¸", "some_college"),
    ("ëŒ€ì¡¸", "college"),
    ("ê³ ì¡¸", "high_school"),
    ("í•™ë ¥ë¬´ê´€", "no")
]

def map_education(text):
    if pd.isna(text):
        return "uncertain"
    for k, v in edu_map:
        if k in text:
            return v
    return "uncertain"

df["job_education"] = df["job_edu"].apply(map_education)


# (5-iii) contract type
df["job_contract_stripped"] = df["job_contract"].astype(str).str.replace(" ", "", regex=False)

df["job_regular"] = df["job_contract_stripped"].apply(lambda x: 1 if "ì •ê·œì§" in x else 0)
df["job_irregular"] = df["job_contract_stripped"].apply(lambda x: 1 if ("ê³„ì•½ì§" in x or "ì•„ë¥´ë°”ì´íŠ¸" in x) else 0)
def extract_intern(text):
    match = re.search(r"ìˆ˜ìŠµ\s*(\d+)", text)
    if match:
        return int(match.group(1))
    return 0
def extract_period(text):
    match = re.search(r"ê·¼ë¬´ê¸°ê°„\s*(\d+)", text)
    if match:
        return int(match.group(1))
    return 0
df["job_intern"] = df["job_contract_stripped"].apply(extract_intern)
df["job_period"] = df["job_contract_stripped"].apply(extract_period)
df.loc[(df["job_irregular"] == 1) & (df["job_regular"] == 1), "job_regular"] = 0
df["job_trans"] = df["job_contract"].fillna("").apply(lambda x: 1 if "ì „í™˜" in x else 0)
##D BENEFIT##
# (1) combine all text content of five benefit information groups (since some posts might mix up)
df["benefit_all"] = df[[
    "benefit_insurance", "benefit_bonus",
    "benefit_holiday", "benefit_study", "benefit_convenience"
]].fillna("").agg(" / ".join, axis=1)

# (2) specify the important aspects and corresponding keywords
benefit_keywords = {
    "benefit_insurance_national": ["êµ­ë¯¼ì—°ê¸ˆ"],
    "benefit_insurance_health": ["ê±´ê°•ë³´í—˜"],
    "benefit_insurance_employ": ["ê³ ìš©ë³´í—˜"],
    "benefit_insurance_injury": ["ì‚°ì¬ë³´í—˜"],
    "benefit_insurance_retire": ["í‡´ì§ì—°ê¸ˆ"],

    "benefit_bonus_retire": ["í‡´ì§ê¸ˆ", "í‡´ì§ì—°ê¸ˆ"],
    "benefit_bonus_overtime": ["ì•¼ê°„ê·¼ë¡œìˆ˜ë‹¹", "ì—°ì¥ê·¼ë¡œìˆ˜ë‹¹", "íœ´ì¼ê·¼ë¡œìˆ˜ë‹¹", "íŠ¹ê·¼ìˆ˜ë‹¹", "ë‹¹ì§ë¹„", "ë¹„ìƒê·¼ë¬´ìˆ˜ë‹¹"],
    "benefit_bonus_performance": ["ìš°ìˆ˜ì‚¬ì›", "ì¸ì„¼í‹°ë¸Œ", "ì„±ê³¼ê¸‰", "ë¶„ê¸°í¬ìƒ"],
    "benefit_bonus_seniority": ["ê·¼ì†ìˆ˜ë‹¹", "ì¥ê¸°ê·¼ì†", "ì—°ì°¨ìˆ˜ë‹¹", "ëª…ì ˆìƒì—¬ê¸ˆ"],
    "benefit_bonus_support": ["ê°€ì¡±ìˆ˜ë‹¹", "ê²½ì¡°ì‚¬ë¹„", "ë³µì§€í¬ì¸íŠ¸", "íœ´ê°€ë¹„", "í†µì‹ ë¹„", "ì°¨ëŸ‰ìœ ì§€ë¹„", "ìê¸°ê°œë°œë¹„", "êµìœ¡ë¹„", "ë³µì§€ì¹´ë“œ", "ì˜ë£Œë¹„","ìë…€êµìœ¡"],

    "benefit_holiday_annual": ["ì—°ì°¨"],
    "benefit_holiday_family": ["ê²½ì¡°", "ê²°í˜¼", "ìƒì¡°", "ê°€ì¡±ëŒë´„"],
    "benefit_holiday_mother": ["ì¶œì‚°", "ìœ¡ì•„"],
    "benefit_holiday_father": ["ë°°ìš°ì", "ë‚¨ì„±"],
    "benefit_holiday_sick": ["ë³‘ê°€", "ê±´ê°•ê²€ì§„", "ìœ ê¸‰"],

    "benefit_edu": [
        "êµìœ¡ì§€ì›", "êµìœ¡ë¹„", "ìê²©ì¦", "ìˆ˜ê°•",
        "ì–´í•™ì§€ì›", "ìê¸°ê³„ë°œë¹„", "í•™ìê¸ˆ", "ì‹œí—˜ì‘ì‹œë£Œ","í•´ì™¸ì—°ìˆ˜"
    ],

    "benefit_food": ["ì¤‘ì‹", "ì„ì‹", "ì¡°ì‹", "ì‹ì‚¬", "ì‹ëŒ€", "ì‚¼ì‹œì„¸ë¼", "ê°„ì‹", "ì‹ê¶Œ", "ì‹ë¹„", "êµ¬ë‚´ì‹ë‹¹"],

    "benefit_live": ["ê¸°ìˆ™ì‚¬", "ìˆ™ì†Œ", "ì‚¬íƒ", "ìƒí™œê´€", "í•˜ìˆ™ë¹„", "ê¸°ìˆ™ë¹„"],

    "benefit_transport": [
        "í†µê·¼ë²„ìŠ¤", "ì…”í‹€ë²„ìŠ¤", "êµí†µë¹„ ì§€ì›", "êµí†µë¹„ ì§€ê¸‰", "êµí†µë¹„", "ì°¨ëŸ‰", "ì£¼ì°¨ì¥",
        "ì£¼ì°¨ë¹„", "ì°¨ë¹„", "ì¶œí‡´ê·¼ë²„ìŠ¤", "í†µê·¼ìˆ˜ë‹¨", "êµí†µí¸ì˜", "êµí†µì§€ì›", "ìœ ë¥˜ë¹„"
    ]
}

# (3) apply all keywords to classify benefits
for varname, keywords in benefit_keywords.items():
    df[varname] = df["benefit_all"].apply(
        lambda x: int(any(k in str(x) for k in keywords))
    )


## ENDING ##
df.to_csv("jobkorea_nurse_cleaned.csv", index=False, encoding="utf-8-sig")
print("âœ… Cleaned and saved as jobkorea_nurse_cleaned.csv")

selected_columns = [
    "job_id", "company_name","job_task_str","job_task_vec","job_task_codevec", "job_task_codestr","job_creat", "job_applyon", "job_applyoff","job_experience",
    "job_education","job_regular","job_irregular","job_intern","job_period","job_trans","company_foundedyear","job_quota",
    "applicants_total","applicants_male","applicants_female","applicants_age_25below","applicants_age_2630",
    "applicants_age_3135","applicants_age_3640","applicants_age_4145","applicants_age_46above","applicants_edu_nohs",
    "applicants_edu_hs","applicants_edu_sclg","applicants_edu_clg","applicants_edu_grd","company_type_eng","company_type_cat",
    "Industry_Standardized","company_province","company_city","job_field_cat","job_field_catname","job_pay_lower","job_pay_upper",
    "job_weekday","job_dayon","job_dayoff","benefit_insurance_national","benefit_insurance_health",
    "benefit_insurance_employ","benefit_insurance_injury","benefit_insurance_retire","benefit_bonus_retire","benefit_bonus_overtime",
    "benefit_bonus_performance","benefit_bonus_seniority","benefit_bonus_support","benefit_holiday_annual","benefit_holiday_family",
    "benefit_holiday_mother","benefit_holiday_father","benefit_holiday_sick","benefit_edu","benefit_food","benefit_live","benefit_transport"
]
selected_df = df[selected_columns]
selected_df.to_csv("jobkorea_sample.csv", index=False, encoding="utf-8-sig")


